{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXTHu7dPaAz-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy.special import expit, logit\n",
        "\n",
        "np.random.seed(2025)\n",
        "# 0) SETTINGS\n",
        "N = 1000\n",
        "target_effective_share = 0.55   # calibrate binary outcome base rate\n",
        "sigma_beta_m = 0.25             # prior sd for mediator betas\n",
        "sigma_beta_y = 0.25             # prior sd for outcome betas\n",
        "noise_sd_m = 1.0                # mediator noise before Likert clamping\n",
        "likert_min, likert_max = 1, 5\n",
        "\n",
        "# 1) DRAW \"LAWS\" FOR GENERATING X (no fixed effects)\n",
        "\n",
        "roles = [\"Analyst\", \"Project manager\", \"Developer\", \"Executive director\", \"Other\"]\n",
        "# draw role probabilities at random (Dirichlet) to avoid fixing them\n",
        "role_probs = np.random.dirichlet(np.ones(len(roles))).tolist()\n",
        "role = np.random.choice(roles, size=N, p=role_probs)\n",
        "\n",
        "exp_bins = [\"0-1\", \"2-4\", \"5-7\", \"8+\"]\n",
        "exp_probs = np.random.dirichlet(np.ones(len(exp_bins))).tolist()\n",
        "experience = np.random.choice(exp_bins, size=N, p=exp_probs)\n",
        "experience_code = pd.Categorical(experience, categories=exp_bins, ordered=True).codes\n",
        "\n",
        "pp_bins = [\"2-3\", \"4-6\", \"7-10\", \"more than 10\"]\n",
        "pp_probs = np.random.dirichlet(np.ones(len(pp_bins))).tolist()\n",
        "peopleparticipation = np.random.choice(pp_bins, size=N, p=pp_probs)\n",
        "peopleparticipation_code = pd.Categorical(peopleparticipation, categories=pp_bins, ordered=True).codes\n",
        "\n",
        "# usage rates drawn from Beta, then Bernoulli\n",
        "p_dashboard = np.random.beta(6, 4)   # mean around 0.6 but random\n",
        "p_ai       = np.random.beta(5, 5)    # mean around 0.5 but random\n",
        "dashboarduse = np.random.binomial(1, p_dashboard, size=N)\n",
        "aiuse       = np.random.binomial(1, p_ai, size=N)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) RANDOM COEFFICIENTS FOR MEDIATORS\n",
        "# Mediators: understanding, access, equity, traceability (values 1â€“5)\n",
        "\n",
        "role_cat = pd.Categorical(role, categories=roles)\n",
        "role_dummies = pd.get_dummies(role_cat, drop_first=True)\n",
        "X_m = pd.concat([\n",
        "    pd.Series(dashboarduse, name=\"dashboarduse\"),\n",
        "    pd.Series(aiuse,       name=\"aiuse\"),\n",
        "    role_dummies,\n",
        "    pd.Series(experience_code, name=\"experience_code\"),\n",
        "    pd.Series(peopleparticipation_code, name=\"peopleparticipation_code\")\n",
        "], axis=1)\n",
        "\n",
        "pred_names = X_m.columns.tolist()\n",
        "import numpy as np\n",
        "\n",
        "def to_likert(latent, min_val=1, max_val=5):\n",
        "    arr = np.asarray(latent, dtype=float).reshape(-1)\n",
        "    arr = np.rint(arr)\n",
        "    arr = np.clip(arr, min_val, max_val)\n",
        "    return arr.astype(np.int64)\n",
        "\n",
        "def draw_mediator(latent_intercept_sd=0.5):\n",
        "    \"\"\"Draw mediator coefficients & generate a Likert 1..5 score.\"\"\"\n",
        "    beta = np.random.normal(0.0, sigma_beta_m, size=X_m.shape[1])\n",
        "    alpha = np.random.normal(3.0, latent_intercept_sd)\n",
        "    latent = alpha + X_m.values @ beta + np.random.normal(0, noise_sd_m, size=N)\n",
        "    likert = to_likert(latent, likert_min, likert_max)\n",
        "    return likert, alpha, beta"
      ],
      "metadata": {
        "id": "GvmyThCVaGQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "understanding, alpha_u, beta_u = draw_mediator()\n",
        "access,        alpha_a, beta_a = draw_mediator()\n",
        "equity,        alpha_e, beta_e = draw_mediator()\n",
        "traceability,  alpha_t, beta_t = draw_mediator()"
      ],
      "metadata": {
        "id": "s7Wxvfe2aiE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) RANDOM COEFFICIENTS FOR BINARY OUTCOME (weak priors)\n",
        "# Outcome predictors: mediators + dashboarduse + aiuse + role dummies + experience_code + peopleparticipation_code\n",
        "\n",
        "X_y = pd.concat([\n",
        "    pd.Series(understanding, name=\"understanding\"),\n",
        "    pd.Series(access,        name=\"access\"),\n",
        "    pd.Series(equity,        name=\"equity\"),\n",
        "    pd.Series(traceability,  name=\"traceability\"),\n",
        "    pd.Series(dashboarduse,  name=\"dashboarduse\"),\n",
        "    pd.Series(aiuse,         name=\"aiuse\"),\n",
        "    role_dummies.add_prefix(\"role_\"),\n",
        "    pd.Series(experience_code, name=\"experience_code\"),\n",
        "    pd.Series(peopleparticipation_code, name=\"peopleparticipation_code\")\n",
        "], axis=1)\n",
        "\n",
        "beta_y = np.random.normal(0.0, sigma_beta_y, size=X_y.shape[1])\n",
        "\n",
        "\n",
        "X_y = X_y.apply(pd.to_numeric, errors=\"raise\")\n",
        "Xy  = X_y.to_numpy(dtype=float, copy=True)\n",
        "beta_y = np.asarray(beta_y, dtype=float)\n",
        "\n",
        "mu = Xy @ beta_y\n",
        "alpha_y = float(logit(target_effective_share) - mu.mean())\n",
        "p_eff = expit(alpha_y + mu)\n",
        "effectiveness = np.random.binomial(1, p_eff, size=N)"
      ],
      "metadata": {
        "id": "rEzHHxvyaoXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4) Assemble dataset\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"role\": role,\n",
        "    \"experience\": experience,\n",
        "    \"experience_code\": experience_code,\n",
        "    \"peopleparticipation\": peopleparticipation,\n",
        "    \"peopleparticipation_code\": peopleparticipation_code,\n",
        "    \"dashboarduse\": dashboarduse,\n",
        "    \"aiuse\": aiuse,\n",
        "    \"understanding\": understanding,\n",
        "    \"access\": access,\n",
        "    \"equity\": equity,\n",
        "    \"traceability\": traceability,\n",
        "    \"effectiveness\": effectiveness\n",
        "})\n",
        "\n",
        "# 5) Save data & realized draws for transparency\n",
        "df.to_csv(\"simulated_collab_survey_1000_randomized.csv\", index=False)\n",
        "\n",
        "draws = {\n",
        "    \"role_probs\": role_probs,\n",
        "    \"exp_probs\": exp_probs,\n",
        "    \"pp_probs\": pp_probs,\n",
        "    \"p_dashboard\": float(p_dashboard),\n",
        "    \"p_ai\": float(p_ai),\n",
        "    \"mediator_coeffs\": {\n",
        "        \"understanding\": {\"alpha\": float(alpha_u), \"beta\": dict(zip(pred_names, beta_u))},\n",
        "        \"access\":        {\"alpha\": float(alpha_a), \"beta\": dict(zip(pred_names, beta_a))},\n",
        "        \"equity\":        {\"alpha\": float(alpha_e), \"beta\": dict(zip(pred_names, beta_e))},\n",
        "        \"traceability\":  {\"alpha\": float(alpha_t), \"beta\": dict(zip(pred_names, beta_t))}\n",
        "    },\n",
        "    \"outcome_coeffs\": {\n",
        "        \"alpha_y\": float(alpha_y),\n",
        "        \"beta_y\": dict(zip(X_y.columns.tolist(), beta_y))\n",
        "    },\n",
        "    \"target_effective_share\": target_effective_share,\n",
        "    \"realized_effective_share\": float(df[\"effectiveness\"].mean())\n",
        "}\n",
        "pd.json_normalize(draws, sep=\"__\").to_json(\"random_draws_summary.json\", orient=\"records\", lines=False)\n",
        "\n",
        "print(\"Saved data to simulated_collab_survey_1000_randomized.csv\")\n",
        "print(\"Saved coefficient draws to random_draws_summary.json\")\n",
        "print(\"Realized effective share:\", round(df['effectiveness'].mean(), 3))"
      ],
      "metadata": {
        "id": "BN1qVLRdayet"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}